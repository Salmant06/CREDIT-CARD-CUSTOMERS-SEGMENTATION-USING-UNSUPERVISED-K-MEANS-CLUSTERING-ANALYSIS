# -*- coding: utf-8 -*-
"""CREDIT_CARD_CUSTOMERS_SEGMENTATION_USING_UNSUPERVISED_K-MEANS_CLUSTERING.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19IXXiFF45EmOXYvYYzoWuxU3D_JscgmX

**CREDIT CARD CUSTOMERS SEGMENTATION USING UNSUPERVISED K-MEANS CLUSTERING ANALYSIS**

#Problem Definition: This system aims to segment credit card customers based on their spending behavior and financial activities. By utilizing K-Means Clustering, we identify distinct customer groups to help banks and financial institutions tailor personalized offers, improve customer service, and reduce churn. The system analyzes transaction features such as balance, purchases, cash advances, credit limits, and payments to categorize customers effectively.

#Use Cases : Customer Segmentation for Targeted Marketing: Identify customer groups with similar spending behavior to offer personalized credit card promotions and rewards
#Risk Management & Credit Limit Adjustments: Banks can assess customer risk levels and optimize credit limit assignments.
#Customer Retention Strategies: Helps in detecting high-value customers and those likely to churn, allowing proactive engagement.
#Spending Pattern Analysis: Provides insights into customer spending habits to improve financial product recommendations.


#Expected Outcome:
#Customers are grouped into meaningful segments based on their spending behavior.
#Financial institutions can tailor marketing strategies, offers, and risk management policies.
#Provides visual insights into customer behavior using clustering techniques.


#Libraries Used:
#Pandas – Data manipulation and cleaning
#NumPy – Numerical computations
#Matplotlib & Seaborn – Data visualization
#Scikit-learn – Machine learning models (K-Means, StandardScaler)
#Yellowbrick – Cluster evaluation (Elbow method, Silhouette analysis)


#Features of the System:
#Data Preprocessing & Cleaning: Handles missing values and standardizes numerical data.
#Exploratory Data Analysis (EDA): Provides descriptive statistics, correlation heatmaps, and pair plots.
#K-Means Clustering: Groups customers into segments based on financial activities.
#Optimal Cluster Selection: Uses Elbow Method and Silhouette Score to determine the best number of clusters.
#Cluster Visualization: Scatter plots and pair plots to interpret clustering results.
#Business Insights: Derives meaningful customer insights for decision-making.


#Conclusion: This customer segmentation system helps banks understand customer spending patterns, optimize marketing strategies, and enhance risk management. Using K-Means Clustering, it provides data-driven insights into different customer segments, allowing businesses to make informed decisions and improve customer engagement.
"""

## 1. Importing Python Libraries
import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, silhouette_samples

from yellowbrick.cluster import SilhouetteVisualizer
from yellowbrick.cluster import KElbowVisualizer

# Data Import and Loading
# Importing the Credit Card Bank Customers Data stored in the csv file

raw_data = pd.read_csv("/content/credit_card_customers.csv")

# Exploratory Data Analysis and Data Cleaning
# Displaying the Shape of the Raw Data

raw_data.shape

# Displaying the First 5 Data Instances of the Raw Data

raw_data.head()

# Displaying the Last 5 Data Instances of the Raw Data

raw_data.tail()

# Displaying the Attributes/Columns in the Raw Data

raw_data.columns

# Displaying the Data Types of the Attributes/Columns in the Raw Data

raw_data.dtypes

# Displaying the Descriptive Statistics of all the Attributes/Columns in the Raw Data

raw_data.describe()

# Identifying the Missing Values
# Displaying the Missing Values in the Raw Data

missing_values = raw_data.isna().sum()
missing_values

# Fixing and Cleaning the Missing Data
raw_data = raw_data.fillna(raw_data['MINIMUM_PAYMENTS'].median())

# Verifying the Missing Values in the Raw Data after updating with the Median Values

raw_data.isna().sum()

# Drop non-numeric columns
raw_data = raw_data.drop(columns=['CUST_ID'])

# Co-relation Between Various Features
# Displaying the Co-relation between the various attributes/features

corr_map = raw_data.corr()
corr_map

# Co-variance Between Various Features
raw_data.cov()

# Co-relation Heatmap Between Various Features
# Visualising the Co-relation Heatmap between the various attributes/features

plt.figure(figsize=(20,10), dpi=80)
sns.heatmap(corr_map, vmin=-1, vmax=1, center=0, annot=True, annot_kws={'size':8}, fmt='.2f')

# Data Pre-processing and Scaling
# Creating a copy of the Raw Data for Scaling Purposes

cust_data = raw_data.copy()
cust_data

# Creating a list of all the Required Features

features = []

for column in cust_data:
    features.append(column)

features

# Defining an Instance of the StandardScaler Function
scalar = StandardScaler()

# Scaling all the Features of the Customer Data
cust_data = scalar.fit_transform(cust_data)

# Displaying the Scaled Numpy Array
cust_data

# Converting the Numpy Array back to a Pandas DataFrame
cust_data = pd.DataFrame(cust_data, columns=features)

# Displaying the Pandas DataFrame with the Scaled Features
cust_data

# Defining the Number of Clusters Ranging from 1 to 20
clusters = range(1, 21)

# Defining an Empty List to Hold the Values of the Sum of the Squared Distances of the Data Points within each Cluster from it's Corresponding Centroid
WCSS = []

# K-Means Clustering Algorithm - Default Parameters Configuration
algorithm = 'auto'
copy_x = True,
init = 'k-means++'
max_iter = 300
n_clusters = clusters
n_init = 10
n_jobs = None
precompute_distances = 'auto'
random_state = 0
tol = 0.0001
verbose = 0

print("K-Means Clustering Model - Initital Configuration Completed")

# Fitting the K-Means Clustering Model for Various Number of Clusters


print("K-Means Model Fitting Started...\n")

for k in clusters:
    kmeans = KMeans(
        algorithm='lloyd',  # Use 'lloyd' or 'elkan'
        copy_x=True,  # Ensure this is a boolean, not a tuple
        init=init,
        max_iter=max_iter,
        n_clusters=k,
        n_init=n_init,
        random_state=random_state,
        tol=tol,
        verbose=verbose
    )
    kmeans = kmeans.fit(cust_data)
    WCSS.append(kmeans.inertia_)
    print("K-Means Model Fitting for {} Clusters Completed...".format(k))

print("\nK-Means Model Fitting Completed...")

# Visualizing the WCSS Method Results
plt.plot(WCSS, 'bo-', label="WCSS")
plt.title("K-Means: Cluster versus WCSS Quality Metrics Computations")
plt.xlabel("Number of Clusters")
plt.ylabel("WCSS")
plt.show()

# Defining the Number of Clusters Ranging from 2 to 20
clusters = range(2, 21)

# Defining an Empty List to Hold the Values of the Silhouette Scores for the Various Number of Clusters
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

sil_score = []

X = cust_data
metric = 'euclidean'
sample_size = None
random_state = None

print("Silhouette Score Computation Started...\n")

for k in clusters:
    kmeans2 = KMeans(
        algorithm='lloyd',  # Use 'lloyd' or 'elkan'
        copy_x=True,
        init='k-means++',
        max_iter=300,
        n_clusters=k,
        n_init=10,
        random_state=random_state,
        tol=1e-4,
        verbose=0
    )
    y_pred = kmeans2.fit_predict(cust_data)
    centres = kmeans2.cluster_centers_
    score = silhouette_score(X=X, labels=y_pred, metric=metric, sample_size=sample_size, random_state=random_state)
    sil_score.append(score)
    print("Number of Clusters is {} and Silhouette Score is {}".format(k, score))
    # Uncomment the next line if you want to print cluster centers
    # print("Cluster Centres are: ", centres)

# Matplot - Visualising the Silhouette Scores for the various Number of Clusters of the K-Means Clustering UnSupervised Algorithm

plt.plot(sil_score, 'go-', label="Silhouette Scores")
plt.title("K-Means: Cluster versus Silhouette Score Quality Metrics Computations")
plt.xlabel("Number of Clusters")
plt.ylabel("Silhouette Score")
plt.show()

# Initialising and Defining a K-Means Model
kmeans3 = KMeans()

# Initialising and Defining a Elbow Visualizer
elbow_visualizer = KElbowVisualizer(kmeans3, k=(2, 21), metric='silhouette', timings=True)

# Fitting the Model
elbow_visualizer.fit(cust_data)

# Visualizing the Results
elbow_visualizer.show()

# Initialising and Defining a K-Means Model
kmeans4 = KMeans(3)

# Initialising and Defining a Silhouette Visualizer
Silhouette_visualizer = SilhouetteVisualizer(kmeans4, colors='yellowbrick')

# Fitting the Model
Silhouette_visualizer.fit(cust_data)

# Visualizing the Results
Silhouette_visualizer.poof()

# K-Means Clustering Algorithm - Default Parameters Configuration
algorithm = 'auto'
copy_x = True,
init = 'k-means++'
max_iter = 300
n_clusters = 3
n_init = 10
n_jobs = None
precompute_distances = 'auto'
random_state = 0
tol = 0.0001
verbose = 0

# Fitting the K-Means Clustering Finalised Model Based on the Finalised Parameters Configured

print("K-Means Finalised Model Fitting Started...")

kmeans_final = KMeans(algorithm=algorithm, copy_x=copy_x, init=init, max_iter=max_iter,
                      n_clusters=n_clusters, n_init=n_init, random_state=random_state,
                      tol=tol, verbose=verbose)

# Fitting the Finalised K-Means Model and Retrieving the Cluster Predictions Outcomes
from sklearn.cluster import KMeans

# Ensure you configure the KMeans model correctly
kmeans_final = KMeans(
    algorithm='lloyd',  # Use 'lloyd' or 'elkan'
    copy_x=True,
    init='k-means++',
    max_iter=300,
    n_clusters=5,  # Example: change to your desired number of clusters
    n_init=10,
    random_state=42,
    tol=1e-4
)

# Fit and predict
y_pred_final = kmeans_final.fit_predict(cust_data)
print("Final predictions:", y_pred_final)

# Displaying all the Cluster Predicted Labels for all the Samples

kmeans_final.labels_

# Appending the Final Predictions Cluster Labels to the Original Non-Sclaed Raw DataFrame

raw_data["Cluster Labels"] = y_pred_final

# Displaying the Final Data Frame with Cluster Labels Predictions Appended
raw_data

# Extracting all the Required Features/Columns as a List By Excluding the "CUST_ID" Column

columns = list(raw_data.columns[1:])
columns

# Seaborn Pair Plot - Visualization for all the Required Features

sns.pairplot(raw_data[columns], hue='Cluster Labels', palette='Set1')

# K-Means Clustering Algorithm - Default Parameters Configuration
algorithm = 'auto'
copy_x = True,
init = 'k-means++'
max_iter = 300
n_clusters = 3
n_init = 10
n_jobs = None
precompute_distances = 'auto'
random_state = 0
tol = 0.0001
verbose = 0

# Business Scenario 1 - BALANCE versus PURCHASES
# Seaborn Scatter Plot - Visualization - Business Scenario 1

subset_columns_1 = ['BALANCE', 'PURCHASES']

kmeans_final_subset_1 = KMeans(algorithm=algorithm, copy_x=copy_x, init=init, max_iter=max_iter,
                               n_clusters=n_clusters, n_init=n_init, random_state=random_state,
                               tol=tol, verbose=verbose)

# Fitting the Finalised K-Means Model and Retrieving the Cluster Predictions Outcomes
from sklearn.cluster import KMeans
import seaborn as sns

# Ensure correct initialization of the KMeans model
kmeans_final_subset_1 = KMeans(
    algorithm='lloyd',  # Use 'lloyd' or 'elkan'
    copy_x=True,
    init='k-means++',
    max_iter=300,
    n_clusters=5,  # Adjust to your desired number of clusters
    n_init=10,
    random_state=42,
    tol=1e-4
)

# Fit the model and predict
y_pred_final_subset_1 = kmeans_final_subset_1.fit_predict(cust_data[subset_columns_1])

# Add cluster predictions to the raw data
raw_data['Cluster Subset 1'] = y_pred_final_subset_1

# Update the subset columns
subset_columns_1.append('Cluster Subset 1')

# Visualize the clusters using a scatter plot
sns.scatterplot(
    x=raw_data['BALANCE'],
    y=raw_data['PURCHASES'],
    hue=raw_data['Cluster Subset 1'],
    palette='Set1'
)

# Verifying the Count and the Percentages of the Customers in each of the 3 Clusters/Labels

cluster_labels_unique = pd.unique(raw_data['Cluster Subset 1'])

cluster_cust_count = raw_data['Cluster Subset 1'].value_counts()

total_cust_count = cluster_cust_count[cluster_labels_unique[0]] + cluster_cust_count[cluster_labels_unique[1]] + cluster_cust_count[cluster_labels_unique[2]]


#print("Total Customer in Cluster Label 0: ", cluster_cust_count[cluster_labels_unique[0]])
#print("Total Customer in Cluster Label 1: ", cluster_cust_count[cluster_labels_unique[1]])
#print("Total Customer in Cluster Label 2: ", cluster_cust_count[cluster_labels_unique[2]])

for k in range(0, len(cluster_labels_unique)):
    k_cust_percentage = (cluster_cust_count[k]/total_cust_count)*100
    k_cust_percentage_rounded = round(k_cust_percentage, 0)
    print("\nTotal Customers in Cluster Label {}: {}".format(k, cluster_cust_count[cluster_labels_unique[k]]))
    print("Total % of Customers in Cluster Label {}: {}%".format(k, k_cust_percentage_rounded))

# Seaborn Pair Plot - Visualization - Business Scenario 2

subset_columns_2 = ['BALANCE', 'PURCHASES', 'CASH_ADVANCE', 'CREDIT_LIMIT', 'PAYMENTS', 'MINIMUM_PAYMENTS']

kmeans_final_subset_2 = KMeans(algorithm=algorithm, copy_x=copy_x, init=init, max_iter=max_iter,
                               n_clusters=n_clusters, n_init=n_init, random_state=random_state,
                               tol=tol, verbose=verbose)

# Fitting the Finalised K-Means Model and Retrieving the Cluster Predictions Outcomes
from sklearn.cluster import KMeans
import seaborn as sns

# Initialize the KMeans model with a valid algorithm value
kmeans_final_subset_2 = KMeans(
    algorithm='lloyd',  # Use 'lloyd' or 'elkan'
    copy_x=True,
    init='k-means++',
    max_iter=300,
    n_clusters=5,  # Adjust to the desired number of clusters
    n_init=10,
    random_state=42,
    tol=1e-4
)

# Fit the model and predict clusters
y_pred_final_subset_2 = kmeans_final_subset_2.fit_predict(cust_data[subset_columns_2])

# Add the predicted clusters to the dataset
raw_data['Cluster Subset 2'] = y_pred_final_subset_2

# Update the subset columns list
subset_columns_2.append('Cluster Subset 2')

# Visualize the clusters using a pair plot
sns.pairplot(raw_data[subset_columns_2], hue='Cluster Subset 2', palette='Set1')